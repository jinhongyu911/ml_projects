{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project_08 - Classification (Churn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project description**\n",
    "<br>Beta Bank customers are leaving: little by little, chipping away every month.\n",
    "<br>The bankers figured out it’s cheaper to save the existing customers rather than to attract new ones.\n",
    "<br>We need to predict whether a customer will leave the bank soon. \n",
    "<br>You have the data on clients’ past behavior and termination of contracts with the bank.\n",
    "<br>Build a model with the maximum possible F1 score. To pass the project, you need an F1 score of at least 0.59. Check the F1 for the test set.\n",
    "<br>Additionally, measure the AUC-ROC metric and compare it with the F1.\n",
    "\n",
    "**Project Goal**\n",
    "<br>Analyze the Beta Bank dataset, preprosess and devide the dataset for classification modeling.\n",
    "<br>Examine the balance of classes. Train the model with and without taking into account the imbalance.\n",
    "<br>Apply different models to see which model has the highest F1 score and AUC-ROC metric in predicting users's churn.\n",
    "\n",
    "**Project instructions**\n",
    "<br>Download and prepare the data and perform EDA.\n",
    "<br>Examine the balance of classes.\n",
    "<br>Improve the quality of the model.\n",
    "<br>Use the training set to pick the best parameters. Train different models on training and validation sets.\n",
    "<br>Perform the final testing.\n",
    "\n",
    "**Data description**\n",
    "<br>Features\n",
    "<br>RowNumber — data string index\n",
    "<br>CustomerId — unique customer identifier\n",
    "<br>Surname — surname\n",
    "<br>CreditScore — credit score\n",
    "<br>Geography — country of residence\n",
    "<br>Gender — gender\n",
    "<br>Age — age\n",
    "<br>Tenure — period of maturation for a customer’s fixed deposit (years)\n",
    "<br>Balance — account balance\n",
    "<br>NumOfProducts — number of banking products used by the customer\n",
    "<br>HasCrCard — customer has a credit card\n",
    "<br>IsActiveMember — customer’s activeness\n",
    "<br>EstimatedSalary — estimated salary\n",
    "<br>Target\n",
    "<br>Exited — сustomer has left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/project_03_dataset.csv')\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('~/work/project_datasets/project_03_dataset.csv', index=False, header=list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['RowNumber','Surname', 'CustomerId'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'RowNumber', 'Surname' & 'CustomerId' columns are dropped as these are not necessary features to train the models.\n",
    "<br>The datatypes of the rest of the columns look correct and there are no duplicated rows.\n",
    "<br>'Tenure' column has 909 missing values that need to be addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['Tenure'] = imputer.fit_transform(df[['Tenure']])\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SimpleImputer was used to fill the missing values of 'Tenure' column with the column mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "0          619   42     2.0       0.00              1          1   \n",
      "1          608   41     1.0   83807.86              1          0   \n",
      "2          502   42     8.0  159660.80              3          1   \n",
      "3          699   39     1.0       0.00              2          0   \n",
      "4          850   43     2.0  125510.82              1          1   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
      "0               1        101348.88       1                  0   \n",
      "1               1        112542.58       0                  0   \n",
      "2               0        113931.57       1                  0   \n",
      "3               0         93826.63       0                  0   \n",
      "4               1         79084.10       0                  0   \n",
      "\n",
      "   Geography_Spain  Gender_Male  \n",
      "0                0            0  \n",
      "1                1            0  \n",
      "2                0            0  \n",
      "3                0            0  \n",
      "4                1            0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding was used to separate and transform all the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Exited'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Exited' class has significantly lower observation count compared to the 'Not Exited' class, resulting in class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['Exited'], axis=1)\n",
    "target = df['Exited']\n",
    "\n",
    "seed = 12345\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "                                                        features, target, test_size=0.4, stratify=target, random_state=seed)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "                                                        features_test, target_test, test_size=0.5, stratify=target_test, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was split into 3 parts with the following proportions, with the training set having the most data for training the models.\n",
    "<br>Train: 60%, Valid: 20%, Test: 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train)\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "features_train = scaler.transform(features_train)\n",
    "features_valid = scaler.transform(features_valid)\n",
    "features_test = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler was used to scale/standardize the features to make sure all features are considered equally important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.3107861060329068\n",
      "ROC_AUC_Score: 0.7874451916444971\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(random_state=seed)\n",
    "model_lr.fit(features_train, target_train)\n",
    "target_pred = model_lr.predict(features_valid)\n",
    "target_pred_proba = model_lr.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "f1_result = f1_score(target_valid, target_pred)\n",
    "roc_auc_result = roc_auc_score(target_valid, target_pred_proba)\n",
    "\n",
    "print(f'F1_Score: {f1_result}')\n",
    "print(f'ROC_AUC_Score: {roc_auc_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.5280701754385966\n",
      "ROC_AUC_Score: 0.7936557788944724\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(random_state=seed, class_weight='balanced')\n",
    "model_lr.fit(features_train, target_train)\n",
    "target_pred = model_lr.predict(features_valid)\n",
    "target_pred_proba = model_lr.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "f1_result = f1_score(target_valid, target_pred)\n",
    "roc_auc_result = roc_auc_score(target_valid, target_pred_proba)\n",
    "\n",
    "print(f'F1_Score: {f1_result}')\n",
    "print(f'ROC_AUC_Score: {roc_auc_result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression models were trained with & without the class_weight hyperparameter set as 'balanced'.\n",
    "<br>The F1_score and ROC_AUC_score both improved quite significantly when the dataset class weights are balanced out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.5855161787365177\n",
      "ROC_AUC_Score: 0.872268819588137\n",
      "{'max_depth': 10, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=seed)\n",
    "params_rf = {'max_depth': [4, 6, 8, 10],\n",
    "            'n_estimators': [200, 250, 300, 350]}\n",
    "gscv = GridSearchCV(rf, param_grid=params_rf, cv=5, n_jobs=-1)\n",
    "gscv.fit(features_train, target_train)\n",
    "best_model = gscv.best_estimator_\n",
    "\n",
    "target_pred = best_model.predict(features_valid)\n",
    "target_pred_proba = best_model.predict_proba(features_valid)[:, 1]\n",
    "f1_result = f1_score(target_valid, target_pred)\n",
    "roc_auc_result = roc_auc_score(target_valid, target_pred_proba)\n",
    "\n",
    "print(f'F1_Score: {f1_result}')\n",
    "print(f'ROC_AUC_Score: {roc_auc_result}')\n",
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV was used to find the best RandomForestRegressor parameters, optimizing based on 'max_depth' & 'n_estimators'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.6329723225030084\n",
      "ROC_AUC_Score: 0.8711788107202679\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=250, max_depth=10, random_state=seed, class_weight='balanced')\n",
    "model_rf.fit(features_train, target_train)\n",
    "target_pred = model_rf.predict(features_valid)\n",
    "target_pred_proba = model_rf.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "f1_result = f1_score(target_valid, target_pred)\n",
    "roc_auc_result = roc_auc_score(target_valid, target_pred_proba)\n",
    "\n",
    "print(f'F1_Score: {f1_result}')\n",
    "print(f'ROC_AUC_Score: {roc_auc_result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegressor models were trained with & without the class_weight hyperparameter set as 'balanced'.\n",
    "<br>The F1_score and ROC_AUC_score both improved quite significantly when the dataset class weights are balanced out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_zeros_df = pd.DataFrame(features_zeros)\n",
    "    features_ones_df = pd.DataFrame(features_ones)\n",
    "    target_zeros_df = pd.Series(target_zeros)\n",
    "    target_ones_df = pd.Series(target_ones)\n",
    "    \n",
    "    features_upsampled = pd.concat([features_zeros_df] + [features_ones_df] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros_df] + [target_ones_df] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=seed)\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An upsampling method was used as an alternative way to balance the class weights of the training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.5246753246753246\n",
      "ROC_AUC_Score: 0.7937558503300819\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(random_state=seed, solver='liblinear')\n",
    "model_lr.fit(features_upsampled, target_upsampled)\n",
    "target_pred = model_lr.predict(features_valid)\n",
    "target_pred_proba = model_lr.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "f1_result = f1_score(target_valid, target_pred)\n",
    "roc_auc_result = roc_auc_score(target_valid, target_pred_proba)\n",
    "\n",
    "print(f'F1_Score: {f1_result}')\n",
    "print(f'ROC_AUC_Score: {roc_auc_result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A LogisticRegression model using the upsampling method performed better than setting the class_weight hyperparameter to 'balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.6445182724252492\n",
      "ROC_AUC_Score: 0.8714590107399744\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=250, max_depth=10, random_state=seed)\n",
    "model_rf.fit(features_upsampled, target_upsampled)\n",
    "target_pred = model_rf.predict(features_valid)\n",
    "target_pred_proba = model_rf.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "f1_result = f1_score(target_valid, target_pred)\n",
    "roc_auc_result = roc_auc_score(target_valid, target_pred_proba)\n",
    "\n",
    "print(f'F1_Score: {f1_result}')\n",
    "print(f'ROC_AUC_Score: {roc_auc_result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RandomForestRegression model using the upsampling method performed better than setting the class_weight hyperparameter to 'balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.6033519553072626\n",
      "ROC_AUC_Score: 0.855482601245313\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=250, max_depth=10, random_state=seed)\n",
    "model_rf.fit(features_upsampled, target_upsampled)\n",
    "target_pred = model_rf.predict(features_test)\n",
    "target_pred_proba = model_rf.predict_proba(features_test)[:, 1]\n",
    "\n",
    "f1_result = f1_score(target_test, target_pred)\n",
    "roc_auc_result = roc_auc_score(target_test, target_pred_proba)\n",
    "\n",
    "print(f'F1_Score: {f1_result}')\n",
    "print(f'ROC_AUC_Score: {roc_auc_result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a RandomForestRegression model trained with upsampled training dataset was used on the test dataset.\n",
    "<br>The final F1_Score was 0.60, which is above the required threshold of 0.59. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In the dataset, 'Exited' class was significantly lower compared to the 'Not Exited' class, resulting in class imbalance.\n",
    "<br>To mitigate this issue, two different approaches were employed.\n",
    "<br>1) The 'class_weight' hyperparameter was set to 'balanced', which assigned higher weights to the 'Exited' class, thus compensating for the class imbalance.\n",
    "<br>2) The 'Exited' class was upsampled, which increased the representation of the 'Exited' class in the training dataset, thereby balancing the class distribution.\n",
    "<br>After several rounds of experimentation, the Random Forest Classifier trained on the upsampled dataset yielded the highest F1 score. The model was then evaluated on the test dataset, and achieved an F1 score of 0.60, surpassing the required threshold of 0.59.\n",
    "<br>Overall, upsampling the minority('Exited') class and training a Random Forest Classifier on the upsampled dataset was successful in mitigating the class imbalance issue and achieving a satisfactory F1 score on the test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
